* 
* ==> Audit <==
* |---------|-----------------|----------|-----------------------|---------|---------------------|----------|
| Command |      Args       | Profile  |         User          | Version |     Start Time      | End Time |
|---------|-----------------|----------|-----------------------|---------|---------------------|----------|
| start   | --driver=docker | minikube | LAPTOP-RDDVU1NH\rupes | v1.30.1 | 01 Jan 24 11:16 IST |          |
| start   | --driver=docker | minikube | LAPTOP-RDDVU1NH\rupes | v1.30.1 | 01 Jan 24 11:20 IST |          |
|---------|-----------------|----------|-----------------------|---------|---------------------|----------|

* 
* ==> Last Start <==
* Log file created at: 2024/01/01 11:20:57
Running on machine: LAPTOP-RDDVU1NH
Binary: Built with gc go1.20.2 for windows/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0101 11:20:57.180745   21972 out.go:296] Setting OutFile to fd 100 ...
I0101 11:20:57.180745   21972 out.go:343] TERM=,COLORTERM=, which probably does not support color
I0101 11:20:57.180745   21972 out.go:309] Setting ErrFile to fd 104...
I0101 11:20:57.180745   21972 out.go:343] TERM=,COLORTERM=, which probably does not support color
W0101 11:20:57.192255   21972 root.go:312] Error reading config file at C:\Users\rupes\.minikube\config\config.json: open C:\Users\rupes\.minikube\config\config.json: The system cannot find the file specified.
I0101 11:20:57.199307   21972 out.go:303] Setting JSON to false
I0101 11:20:57.207129   21972 start.go:125] hostinfo: {"hostname":"LAPTOP-RDDVU1NH","uptime":310745,"bootTime":1703777511,"procs":334,"os":"windows","platform":"Microsoft Windows 11 Home Single Language","platformFamily":"Standalone Workstation","platformVersion":"10.0.22621.2861 Build 22621.2861","kernelVersion":"10.0.22621.2861 Build 22621.2861","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"a740d7e6-99bb-402f-9aed-32e3e8b77248"}
W0101 11:20:57.207129   21972 start.go:133] gopshost.Virtualization returned error: not implemented yet
I0101 11:20:57.209340   21972 out.go:177] * minikube v1.30.1 on Microsoft Windows 11 Home Single Language 10.0.22621.2861 Build 22621.2861
I0101 11:20:57.210372   21972 notify.go:220] Checking for updates...
I0101 11:20:57.210890   21972 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.26.3
I0101 11:20:57.213504   21972 driver.go:375] Setting default libvirt URI to qemu:///system
I0101 11:20:57.357354   21972 docker.go:121] docker version: linux-20.10.22:Docker Desktop 4.16.3 (96739)
I0101 11:20:57.362125   21972 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0101 11:20:57.788067   21972 info.go:266] docker info: {ID:3QPW:EHZT:QBGZ:CQRI:TAHZ:5EZ2:PHYN:2IOQ:PULU:KHJW:B7GX:N5HE Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:8 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:60 OomKillDisable:true NGoroutines:58 SystemTime:2024-01-01 05:50:57.449809932 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:6 KernelVersion:5.15.133.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:8216616960 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.22 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:9ba4b250366a5ddde94bb7c9d1def331423aa323 Expected:9ba4b250366a5ddde94bb7c9d1def331423aa323} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.10.0] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.15.1] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.0.5] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.17] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.23.0]] Warnings:<nil>}}
I0101 11:20:57.791248   21972 out.go:177] * Using the docker driver based on existing profile
I0101 11:20:57.792830   21972 start.go:295] selected driver: docker
I0101 11:20:57.792830   21972 start.go:870] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.26.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\rupes:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0101 11:20:57.792830   21972 start.go:881] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0101 11:20:57.800222   21972 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0101 11:20:58.234696   21972 info.go:266] docker info: {ID:3QPW:EHZT:QBGZ:CQRI:TAHZ:5EZ2:PHYN:2IOQ:PULU:KHJW:B7GX:N5HE Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:8 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:60 OomKillDisable:true NGoroutines:58 SystemTime:2024-01-01 05:50:57.884564228 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:6 KernelVersion:5.15.133.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:8216616960 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.22 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:9ba4b250366a5ddde94bb7c9d1def331423aa323 Expected:9ba4b250366a5ddde94bb7c9d1def331423aa323} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.10.0] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.15.1] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.0.5] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.17] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.23.0]] Warnings:<nil>}}
I0101 11:20:58.314403   21972 cni.go:84] Creating CNI manager for ""
I0101 11:20:58.314403   21972 cni.go:157] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0101 11:20:58.314403   21972 start_flags.go:319] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.26.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\rupes:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0101 11:20:58.315449   21972 out.go:177] * Starting control plane node minikube in cluster minikube
I0101 11:20:58.315971   21972 cache.go:120] Beginning downloading kic base image for docker with docker
I0101 11:20:58.317536   21972 out.go:177] * Pulling base image ...
I0101 11:20:58.318122   21972 preload.go:132] Checking if preload exists for k8s version v1.26.3 and runtime docker
I0101 11:20:58.318122   21972 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 in local docker daemon
I0101 11:20:58.318627   21972 preload.go:148] Found local preload: C:\Users\rupes\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.26.3-docker-overlay2-amd64.tar.lz4
I0101 11:20:58.318627   21972 cache.go:57] Caching tarball of preloaded images
I0101 11:20:58.318627   21972 preload.go:174] Found C:\Users\rupes\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.26.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0101 11:20:58.318627   21972 cache.go:60] Finished verifying existence of preloaded tar for  v1.26.3 on docker
I0101 11:20:58.318627   21972 profile.go:148] Saving config to C:\Users\rupes\.minikube\profiles\minikube\config.json ...
I0101 11:20:58.450682   21972 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 in local docker daemon, skipping pull
I0101 11:20:58.450682   21972 cache.go:143] gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 exists in daemon, skipping load
I0101 11:20:58.450682   21972 cache.go:193] Successfully downloaded all kic artifacts
I0101 11:20:58.450682   21972 start.go:364] acquiring machines lock for minikube: {Name:mk483d9895b5eda288382d7ead22204542e8be92 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0101 11:20:58.450682   21972 start.go:368] acquired machines lock for "minikube" in 0s
I0101 11:20:58.451200   21972 start.go:96] Skipping create...Using existing machine configuration
I0101 11:20:58.451200   21972 fix.go:55] fixHost starting: 
I0101 11:20:58.459254   21972 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0101 11:20:58.573866   21972 fix.go:103] recreateIfNeeded on minikube: state=Running err=<nil>
W0101 11:20:58.573866   21972 fix.go:129] unexpected machine state, will restart: <nil>
I0101 11:20:58.574917   21972 out.go:177] * Updating the running docker "minikube" container ...
I0101 11:20:58.575948   21972 machine.go:88] provisioning docker machine ...
I0101 11:20:58.575948   21972 ubuntu.go:169] provisioning hostname "minikube"
I0101 11:20:58.579223   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:20:58.697996   21972 main.go:141] libmachine: Using SSH client type: native
I0101 11:20:58.698638   21972 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x468640] 0x46b500 <nil>  [] 0s} 127.0.0.1 50193 <nil> <nil>}
I0101 11:20:58.698638   21972 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0101 11:20:58.844071   21972 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0101 11:20:58.848348   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:20:58.978261   21972 main.go:141] libmachine: Using SSH client type: native
I0101 11:20:58.979089   21972 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x468640] 0x46b500 <nil>  [] 0s} 127.0.0.1 50193 <nil> <nil>}
I0101 11:20:58.979089   21972 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0101 11:20:59.112537   21972 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0101 11:20:59.112537   21972 ubuntu.go:175] set auth options {CertDir:C:\Users\rupes\.minikube CaCertPath:C:\Users\rupes\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\rupes\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\rupes\.minikube\machines\server.pem ServerKeyPath:C:\Users\rupes\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\rupes\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\rupes\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\rupes\.minikube}
I0101 11:20:59.112537   21972 ubuntu.go:177] setting up certificates
I0101 11:20:59.112537   21972 provision.go:83] configureAuth start
I0101 11:20:59.119103   21972 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0101 11:20:59.235707   21972 provision.go:138] copyHostCerts
I0101 11:20:59.235707   21972 exec_runner.go:144] found C:\Users\rupes\.minikube/ca.pem, removing ...
I0101 11:20:59.235707   21972 exec_runner.go:207] rm: C:\Users\rupes\.minikube\ca.pem
I0101 11:20:59.236262   21972 exec_runner.go:151] cp: C:\Users\rupes\.minikube\certs\ca.pem --> C:\Users\rupes\.minikube/ca.pem (1074 bytes)
I0101 11:20:59.237157   21972 exec_runner.go:144] found C:\Users\rupes\.minikube/cert.pem, removing ...
I0101 11:20:59.237157   21972 exec_runner.go:207] rm: C:\Users\rupes\.minikube\cert.pem
I0101 11:20:59.237220   21972 exec_runner.go:151] cp: C:\Users\rupes\.minikube\certs\cert.pem --> C:\Users\rupes\.minikube/cert.pem (1119 bytes)
I0101 11:20:59.237726   21972 exec_runner.go:144] found C:\Users\rupes\.minikube/key.pem, removing ...
I0101 11:20:59.237726   21972 exec_runner.go:207] rm: C:\Users\rupes\.minikube\key.pem
I0101 11:20:59.237726   21972 exec_runner.go:151] cp: C:\Users\rupes\.minikube\certs\key.pem --> C:\Users\rupes\.minikube/key.pem (1679 bytes)
I0101 11:20:59.238252   21972 provision.go:112] generating server cert: C:\Users\rupes\.minikube\machines\server.pem ca-key=C:\Users\rupes\.minikube\certs\ca.pem private-key=C:\Users\rupes\.minikube\certs\ca-key.pem org=rupes.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0101 11:20:59.271061   21972 provision.go:172] copyRemoteCerts
I0101 11:20:59.278560   21972 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0101 11:20:59.282552   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:20:59.404516   21972 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50193 SSHKeyPath:C:\Users\rupes\.minikube\machines\minikube\id_rsa Username:docker}
I0101 11:20:59.505902   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1074 bytes)
I0101 11:20:59.520988   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\machines\server.pem --> /etc/docker/server.pem (1196 bytes)
I0101 11:20:59.537005   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0101 11:20:59.550853   21972 provision.go:86] duration metric: configureAuth took 438.316ms
I0101 11:20:59.550853   21972 ubuntu.go:193] setting minikube options for container-runtime
I0101 11:20:59.550853   21972 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.26.3
I0101 11:20:59.554608   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:20:59.667290   21972 main.go:141] libmachine: Using SSH client type: native
I0101 11:20:59.667812   21972 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x468640] 0x46b500 <nil>  [] 0s} 127.0.0.1 50193 <nil> <nil>}
I0101 11:20:59.667812   21972 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0101 11:20:59.798757   21972 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0101 11:20:59.798757   21972 ubuntu.go:71] root file system type: overlay
I0101 11:20:59.799281   21972 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0101 11:20:59.803056   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:20:59.929300   21972 main.go:141] libmachine: Using SSH client type: native
I0101 11:20:59.929996   21972 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x468640] 0x46b500 <nil>  [] 0s} 127.0.0.1 50193 <nil> <nil>}
I0101 11:20:59.929996   21972 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0101 11:21:00.073907   21972 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0101 11:21:00.077632   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:21:00.208673   21972 main.go:141] libmachine: Using SSH client type: native
I0101 11:21:00.209182   21972 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x468640] 0x46b500 <nil>  [] 0s} 127.0.0.1 50193 <nil> <nil>}
I0101 11:21:00.209182   21972 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0101 11:21:00.345989   21972 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0101 11:21:00.345989   21972 machine.go:91] provisioned docker machine in 1.7700418s
I0101 11:21:00.345989   21972 start.go:300] post-start starting for "minikube" (driver="docker")
I0101 11:21:00.345989   21972 start.go:328] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0101 11:21:00.354533   21972 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0101 11:21:00.358308   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:21:00.481383   21972 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50193 SSHKeyPath:C:\Users\rupes\.minikube\machines\minikube\id_rsa Username:docker}
I0101 11:21:00.594127   21972 ssh_runner.go:195] Run: cat /etc/os-release
I0101 11:21:00.598072   21972 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0101 11:21:00.598072   21972 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0101 11:21:00.598072   21972 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0101 11:21:00.598072   21972 info.go:137] Remote host: Ubuntu 20.04.5 LTS
I0101 11:21:00.598584   21972 filesync.go:126] Scanning C:\Users\rupes\.minikube\addons for local assets ...
I0101 11:21:00.598584   21972 filesync.go:126] Scanning C:\Users\rupes\.minikube\files for local assets ...
I0101 11:21:00.598584   21972 start.go:303] post-start completed in 252.595ms
I0101 11:21:00.607182   21972 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0101 11:21:00.610996   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:21:00.726930   21972 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50193 SSHKeyPath:C:\Users\rupes\.minikube\machines\minikube\id_rsa Username:docker}
I0101 11:21:00.829687   21972 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0101 11:21:00.834490   21972 fix.go:57] fixHost completed within 2.3832898s
I0101 11:21:00.834490   21972 start.go:83] releasing machines lock for "minikube", held for 2.3838074s
I0101 11:21:00.838204   21972 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0101 11:21:00.958796   21972 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0101 11:21:00.963831   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:21:00.967894   21972 ssh_runner.go:195] Run: cat /version.json
I0101 11:21:00.971637   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0101 11:21:01.094927   21972 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50193 SSHKeyPath:C:\Users\rupes\.minikube\machines\minikube\id_rsa Username:docker}
I0101 11:21:01.107593   21972 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50193 SSHKeyPath:C:\Users\rupes\.minikube\machines\minikube\id_rsa Username:docker}
I0101 11:21:01.465222   21972 ssh_runner.go:195] Run: systemctl --version
I0101 11:21:01.478551   21972 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0101 11:21:01.493167   21972 ssh_runner.go:195] Run: sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
W0101 11:21:01.500816   21972 start.go:408] unable to name loopback interface in configureRuntimes: unable to patch loopback cni config "/etc/cni/net.d/*loopback.conf*": sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;: Process exited with status 1
stdout:

stderr:
find: '\\etc\\cni\\net.d': No such file or directory
I0101 11:21:01.509991   21972 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0101 11:21:01.516675   21972 cni.go:258] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0101 11:21:01.516675   21972 start.go:481] detecting cgroup driver to use...
I0101 11:21:01.516675   21972 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0101 11:21:01.517187   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0101 11:21:01.535456   21972 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0101 11:21:01.551175   21972 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0101 11:21:01.558439   21972 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0101 11:21:01.567099   21972 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0101 11:21:01.583245   21972 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0101 11:21:01.599369   21972 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0101 11:21:01.615533   21972 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0101 11:21:01.631438   21972 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0101 11:21:01.647176   21972 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0101 11:21:01.663358   21972 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0101 11:21:01.678803   21972 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0101 11:21:01.694029   21972 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0101 11:21:01.813015   21972 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0101 11:21:01.910005   21972 start.go:481] detecting cgroup driver to use...
I0101 11:21:01.910005   21972 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0101 11:21:01.919043   21972 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0101 11:21:01.928541   21972 cruntime.go:276] skipping containerd shutdown because we are bound to it
I0101 11:21:01.937508   21972 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0101 11:21:01.946441   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0101 11:21:01.965447   21972 ssh_runner.go:195] Run: which cri-dockerd
I0101 11:21:01.978931   21972 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0101 11:21:01.986229   21972 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0101 11:21:02.009184   21972 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0101 11:21:02.094605   21972 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0101 11:21:02.186229   21972 docker.go:538] configuring docker to use "cgroupfs" as cgroup driver...
I0101 11:21:02.186734   21972 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (144 bytes)
I0101 11:21:02.206758   21972 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0101 11:21:02.300133   21972 ssh_runner.go:195] Run: sudo systemctl restart docker
I0101 11:21:02.526795   21972 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0101 11:21:02.618515   21972 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0101 11:21:02.710638   21972 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0101 11:21:02.793771   21972 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0101 11:21:02.888991   21972 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0101 11:21:02.910924   21972 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0101 11:21:03.003133   21972 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0101 11:21:03.055313   21972 start.go:528] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0101 11:21:03.064269   21972 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0101 11:21:03.067999   21972 start.go:549] Will wait 60s for crictl version
I0101 11:21:03.076757   21972 ssh_runner.go:195] Run: which crictl
I0101 11:21:03.089153   21972 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0101 11:21:03.113736   21972 start.go:565] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  23.0.2
RuntimeApiVersion:  v1alpha2
I0101 11:21:03.118092   21972 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0101 11:21:03.142163   21972 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0101 11:21:03.162876   21972 out.go:204] * Preparing Kubernetes v1.26.3 on Docker 23.0.2 ...
I0101 11:21:03.167180   21972 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0101 11:21:03.319317   21972 network.go:96] got host ip for mount in container by digging dns: 192.168.65.2
I0101 11:21:03.327620   21972 ssh_runner.go:195] Run: grep 192.168.65.2	host.minikube.internal$ /etc/hosts
I0101 11:21:03.337113   21972 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0101 11:21:03.459111   21972 preload.go:132] Checking if preload exists for k8s version v1.26.3 and runtime docker
I0101 11:21:03.466870   21972 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0101 11:21:03.486181   21972 docker.go:639] Got preloaded images: -- stdout --
<none>:<none>
<none>:<none>
<none>:<none>
registry.k8s.io/kube-apiserver:v1.26.3
registry.k8s.io/kube-scheduler:v1.26.3
registry.k8s.io/kube-controller-manager:v1.26.3
registry.k8s.io/kube-proxy:v1.26.3
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/pause:3.9
registry.k8s.io/coredns/coredns:v1.9.3
<none>:<none>
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0101 11:21:03.486181   21972 docker.go:569] Images already preloaded, skipping extraction
I0101 11:21:03.489920   21972 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0101 11:21:03.505548   21972 docker.go:639] Got preloaded images: -- stdout --
<none>:<none>
<none>:<none>
<none>:<none>
registry.k8s.io/kube-apiserver:v1.26.3
registry.k8s.io/kube-controller-manager:v1.26.3
registry.k8s.io/kube-scheduler:v1.26.3
registry.k8s.io/kube-proxy:v1.26.3
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/pause:3.9
registry.k8s.io/coredns/coredns:v1.9.3
<none>:<none>
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0101 11:21:03.505548   21972 cache_images.go:84] Images are preloaded, skipping loading
I0101 11:21:03.509324   21972 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0101 11:21:03.528393   21972 cni.go:84] Creating CNI manager for ""
I0101 11:21:03.528393   21972 cni.go:157] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0101 11:21:03.528924   21972 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0101 11:21:03.528924   21972 kubeadm.go:172] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.26.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m]}
I0101 11:21:03.528924   21972 kubeadm.go:177] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.26.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0101 11:21:03.528924   21972 kubeadm.go:968] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.26.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0101 11:21:03.537933   21972 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.26.3
I0101 11:21:03.544340   21972 binaries.go:44] Found k8s binaries, skipping transfer
I0101 11:21:03.553403   21972 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0101 11:21:03.559884   21972 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (369 bytes)
I0101 11:21:03.569600   21972 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0101 11:21:03.579162   21972 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2084 bytes)
I0101 11:21:03.599133   21972 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0101 11:21:03.602644   21972 certs.go:56] Setting up C:\Users\rupes\.minikube\profiles\minikube for IP: 192.168.49.2
I0101 11:21:03.603158   21972 certs.go:186] acquiring lock for shared ca certs: {Name:mk197511f04cd0dd6a90a4b41d04a33b1a84f09a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0101 11:21:03.603158   21972 certs.go:195] skipping minikubeCA CA generation: C:\Users\rupes\.minikube\ca.key
I0101 11:21:03.603158   21972 certs.go:195] skipping proxyClientCA CA generation: C:\Users\rupes\.minikube\proxy-client-ca.key
I0101 11:21:03.603683   21972 certs.go:311] skipping minikube-user signed cert generation: C:\Users\rupes\.minikube\profiles\minikube\client.key
I0101 11:21:03.603683   21972 certs.go:311] skipping minikube signed cert generation: C:\Users\rupes\.minikube\profiles\minikube\apiserver.key.dd3b5fb2
I0101 11:21:03.603683   21972 certs.go:311] skipping aggregator signed cert generation: C:\Users\rupes\.minikube\profiles\minikube\proxy-client.key
I0101 11:21:03.604219   21972 certs.go:401] found cert: C:\Users\rupes\.minikube\certs\C:\Users\rupes\.minikube\certs\ca-key.pem (1679 bytes)
I0101 11:21:03.604749   21972 certs.go:401] found cert: C:\Users\rupes\.minikube\certs\C:\Users\rupes\.minikube\certs\ca.pem (1074 bytes)
I0101 11:21:03.604749   21972 certs.go:401] found cert: C:\Users\rupes\.minikube\certs\C:\Users\rupes\.minikube\certs\cert.pem (1119 bytes)
I0101 11:21:03.604749   21972 certs.go:401] found cert: C:\Users\rupes\.minikube\certs\C:\Users\rupes\.minikube\certs\key.pem (1679 bytes)
I0101 11:21:03.605292   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\profiles\minikube\apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0101 11:21:03.618980   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\profiles\minikube\apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0101 11:21:03.632871   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\profiles\minikube\proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0101 11:21:03.646185   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\profiles\minikube\proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0101 11:21:03.659212   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0101 11:21:03.672068   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0101 11:21:03.685565   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0101 11:21:03.699526   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0101 11:21:03.713466   21972 ssh_runner.go:362] scp C:\Users\rupes\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0101 11:21:03.727522   21972 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0101 11:21:03.745846   21972 ssh_runner.go:195] Run: openssl version
I0101 11:21:03.759940   21972 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0101 11:21:03.776261   21972 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0101 11:21:03.780473   21972 certs.go:444] hashing: -rw-r--r-- 1 root root 1111 Jan  1 05:48 /usr/share/ca-certificates/minikubeCA.pem
I0101 11:21:03.789222   21972 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0101 11:21:03.802916   21972 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0101 11:21:03.809317   21972 kubeadm.go:401] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.26.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\rupes:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0101 11:21:03.813722   21972 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0101 11:21:03.836486   21972 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0101 11:21:03.852215   21972 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0101 11:21:03.858767   21972 kubeadm.go:226] ignoring SystemVerification for kubeadm because of docker driver
I0101 11:21:03.867410   21972 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0101 11:21:03.874375   21972 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0101 11:21:03.874375   21972 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0101 11:21:03.907323   21972 kubeadm.go:322] W0101 05:51:03.906319    8229 initconfiguration.go:119] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
I0101 11:21:03.936856   21972 kubeadm.go:322] 	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
I0101 11:21:04.007337   21972 kubeadm.go:322] 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0101 11:21:04.007337   21972 kubeadm.go:322] 	[WARNING DirAvailable--var-lib-minikube-etcd]: /var/lib/minikube/etcd is not empty
I0101 11:21:04.108683   21972 kubeadm.go:322] error execution phase certs/apiserver-kubelet-client: [certs] certificate apiserver-kubelet-client not signed by CA certificate ca: x509: certificate signed by unknown authority (possibly because of "crypto/rsa: verification error" while trying to verify candidate authority certificate "minikubeCA")
I0101 11:21:04.109737   21972 out.go:204]   - Generating certificates and keys ...
I0101 11:21:04.110265   21972 kubeadm.go:322] To see the stack trace of this error execute with --v=5 or higher
I0101 11:21:04.110265   21972 kubeadm.go:322] [init] Using Kubernetes version: v1.26.3
I0101 11:21:04.110265   21972 kubeadm.go:322] [preflight] Running pre-flight checks
I0101 11:21:04.110793   21972 kubeadm.go:322] [preflight] Pulling images required for setting up a Kubernetes cluster
I0101 11:21:04.110793   21972 kubeadm.go:322] [preflight] This might take a minute or two, depending on the speed of your internet connection
I0101 11:21:04.110793   21972 kubeadm.go:322] [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
I0101 11:21:04.110793   21972 kubeadm.go:322] [certs] Using certificateDir folder "/var/lib/minikube/certs"
I0101 11:21:04.111320   21972 kubeadm.go:322] [certs] Using existing ca certificate authority
I0101 11:21:04.111320   21972 kubeadm.go:322] [certs] Using existing apiserver certificate and key on disk
W0101 11:21:04.111320   21972 out.go:239] ! initialization failed, will try again: wait: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables": Process exited with status 1
stdout:
[init] Using Kubernetes version: v1.26.3
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[certs] Using certificateDir folder "/var/lib/minikube/certs"
[certs] Using existing ca certificate authority
[certs] Using existing apiserver certificate and key on disk

stderr:
W0101 05:51:03.906319    8229 initconfiguration.go:119] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
	[WARNING DirAvailable--var-lib-minikube-etcd]: /var/lib/minikube/etcd is not empty
error execution phase certs/apiserver-kubelet-client: [certs] certificate apiserver-kubelet-client not signed by CA certificate ca: x509: certificate signed by unknown authority (possibly because of "crypto/rsa: verification error" while trying to verify candidate authority certificate "minikubeCA")
To see the stack trace of this error execute with --v=5 or higher

I0101 11:21:04.111841   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.3:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force"
I0101 11:21:06.002406   21972 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.3:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force": (1.8905646s)
I0101 11:21:06.012099   21972 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0101 11:21:06.020282   21972 kubeadm.go:226] ignoring SystemVerification for kubeadm because of docker driver
I0101 11:21:06.029202   21972 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0101 11:21:06.035630   21972 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0101 11:21:06.035630   21972 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0101 11:21:06.068154   21972 kubeadm.go:322] W0101 05:51:06.067129   10635 initconfiguration.go:119] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
I0101 11:21:06.093534   21972 kubeadm.go:322] 	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
I0101 11:21:06.156886   21972 kubeadm.go:322] 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0101 11:21:06.156886   21972 kubeadm.go:322] 	[WARNING DirAvailable--var-lib-minikube-etcd]: /var/lib/minikube/etcd is not empty
I0101 11:21:06.247674   21972 kubeadm.go:322] error execution phase certs/apiserver-kubelet-client: [certs] certificate apiserver-kubelet-client not signed by CA certificate ca: x509: certificate signed by unknown authority (possibly because of "crypto/rsa: verification error" while trying to verify candidate authority certificate "minikubeCA")
I0101 11:21:06.250313   21972 out.go:204]   - Generating certificates and keys ...
I0101 11:21:06.250836   21972 kubeadm.go:322] To see the stack trace of this error execute with --v=5 or higher
I0101 11:21:06.250836   21972 kubeadm.go:322] [init] Using Kubernetes version: v1.26.3
I0101 11:21:06.250836   21972 kubeadm.go:322] [preflight] Running pre-flight checks
I0101 11:21:06.250836   21972 kubeadm.go:322] [preflight] Pulling images required for setting up a Kubernetes cluster
I0101 11:21:06.250836   21972 kubeadm.go:322] [preflight] This might take a minute or two, depending on the speed of your internet connection
I0101 11:21:06.251360   21972 kubeadm.go:322] [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
I0101 11:21:06.251360   21972 kubeadm.go:322] [certs] Using certificateDir folder "/var/lib/minikube/certs"
I0101 11:21:06.251360   21972 kubeadm.go:322] [certs] Using existing ca certificate authority
I0101 11:21:06.251360   21972 kubeadm.go:322] [certs] Using existing apiserver certificate and key on disk
I0101 11:21:06.251360   21972 kubeadm.go:403] StartCluster complete in 2.4420431s
I0101 11:21:06.251360   21972 cri.go:52] listing CRI containers in root : {State:all Name:kube-apiserver Namespaces:[]}
I0101 11:21:06.260002   21972 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kube-apiserver
I0101 11:21:06.280145   21972 cri.go:87] found id: ""
I0101 11:21:06.280145   21972 logs.go:277] 0 containers: []
W0101 11:21:06.280145   21972 logs.go:279] No container was found matching "kube-apiserver"
I0101 11:21:06.280145   21972 cri.go:52] listing CRI containers in root : {State:all Name:etcd Namespaces:[]}
I0101 11:21:06.289287   21972 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=etcd
I0101 11:21:06.308140   21972 cri.go:87] found id: ""
I0101 11:21:06.308140   21972 logs.go:277] 0 containers: []
W0101 11:21:06.308140   21972 logs.go:279] No container was found matching "etcd"
I0101 11:21:06.308140   21972 cri.go:52] listing CRI containers in root : {State:all Name:coredns Namespaces:[]}
I0101 11:21:06.316781   21972 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=coredns
I0101 11:21:06.335395   21972 cri.go:87] found id: "150b91fc9e61cb2d19d130a399871243a41a7a2d051e99e20836f156b3746183"
I0101 11:21:06.335395   21972 cri.go:87] found id: "f6323d482fd350975cf1695c0e58a14ad73905b2c590956567979e16eeaaeb80"
I0101 11:21:06.335395   21972 cri.go:87] found id: ""
I0101 11:21:06.335395   21972 logs.go:277] 2 containers: [150b91fc9e61cb2d19d130a399871243a41a7a2d051e99e20836f156b3746183 f6323d482fd350975cf1695c0e58a14ad73905b2c590956567979e16eeaaeb80]
I0101 11:21:06.344038   21972 ssh_runner.go:195] Run: which crictl
I0101 11:21:06.356042   21972 ssh_runner.go:195] Run: which crictl
I0101 11:21:06.359234   21972 cri.go:52] listing CRI containers in root : {State:all Name:kube-scheduler Namespaces:[]}
I0101 11:21:06.368285   21972 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kube-scheduler
I0101 11:21:06.387617   21972 cri.go:87] found id: ""
I0101 11:21:06.387617   21972 logs.go:277] 0 containers: []
W0101 11:21:06.387617   21972 logs.go:279] No container was found matching "kube-scheduler"
I0101 11:21:06.387617   21972 cri.go:52] listing CRI containers in root : {State:all Name:kube-proxy Namespaces:[]}
I0101 11:21:06.396498   21972 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kube-proxy
I0101 11:21:06.416315   21972 cri.go:87] found id: ""
I0101 11:21:06.416315   21972 logs.go:277] 0 containers: []
W0101 11:21:06.416315   21972 logs.go:279] No container was found matching "kube-proxy"
I0101 11:21:06.416315   21972 cri.go:52] listing CRI containers in root : {State:all Name:kube-controller-manager Namespaces:[]}
I0101 11:21:06.424934   21972 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kube-controller-manager
I0101 11:21:06.443004   21972 cri.go:87] found id: ""
I0101 11:21:06.443004   21972 logs.go:277] 0 containers: []
W0101 11:21:06.443004   21972 logs.go:279] No container was found matching "kube-controller-manager"
I0101 11:21:06.443004   21972 cri.go:52] listing CRI containers in root : {State:all Name:kindnet Namespaces:[]}
I0101 11:21:06.451784   21972 ssh_runner.go:195] Run: sudo crictl ps -a --quiet --name=kindnet
I0101 11:21:06.471200   21972 cri.go:87] found id: ""
I0101 11:21:06.471200   21972 logs.go:277] 0 containers: []
W0101 11:21:06.471200   21972 logs.go:279] No container was found matching "kindnet"
I0101 11:21:06.471200   21972 logs.go:123] Gathering logs for container status ...
I0101 11:21:06.471200   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0101 11:21:06.492965   21972 logs.go:123] Gathering logs for kubelet ...
I0101 11:21:06.492965   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0101 11:21:06.501015   21972 logs.go:123] Gathering logs for dmesg ...
I0101 11:21:06.501015   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0101 11:21:06.510262   21972 logs.go:123] Gathering logs for describe nodes ...
I0101 11:21:06.510262   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0101 11:21:06.569971   21972 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0101 05:51:06.561043   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0101 05:51:06.561575   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0101 05:51:06.563278   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0101 05:51:06.564374   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0101 05:51:06.566173   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0101 05:51:06.561043   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0101 05:51:06.561575   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0101 05:51:06.563278   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0101 05:51:06.564374   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0101 05:51:06.566173   10876 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0101 11:21:06.569971   21972 logs.go:123] Gathering logs for coredns [150b91fc9e61cb2d19d130a399871243a41a7a2d051e99e20836f156b3746183] ...
I0101 11:21:06.569971   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo /usr/bin/crictl logs --tail 400 150b91fc9e61cb2d19d130a399871243a41a7a2d051e99e20836f156b3746183"
I0101 11:21:06.590756   21972 logs.go:123] Gathering logs for coredns [f6323d482fd350975cf1695c0e58a14ad73905b2c590956567979e16eeaaeb80] ...
I0101 11:21:06.590756   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo /usr/bin/crictl logs --tail 400 f6323d482fd350975cf1695c0e58a14ad73905b2c590956567979e16eeaaeb80"
I0101 11:21:06.612579   21972 logs.go:123] Gathering logs for Docker ...
I0101 11:21:06.612579   21972 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
W0101 11:21:06.667998   21972 out.go:369] Error starting cluster: wait: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables": Process exited with status 1
stdout:
[init] Using Kubernetes version: v1.26.3
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[certs] Using certificateDir folder "/var/lib/minikube/certs"
[certs] Using existing ca certificate authority
[certs] Using existing apiserver certificate and key on disk

stderr:
W0101 05:51:06.067129   10635 initconfiguration.go:119] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
	[WARNING DirAvailable--var-lib-minikube-etcd]: /var/lib/minikube/etcd is not empty
error execution phase certs/apiserver-kubelet-client: [certs] certificate apiserver-kubelet-client not signed by CA certificate ca: x509: certificate signed by unknown authority (possibly because of "crypto/rsa: verification error" while trying to verify candidate authority certificate "minikubeCA")
To see the stack trace of this error execute with --v=5 or higher
W0101 11:21:06.667998   21972 out.go:239] * 
W0101 11:21:06.667998   21972 out.go:239] X Error starting cluster: wait: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables": Process exited with status 1
stdout:
[init] Using Kubernetes version: v1.26.3
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[certs] Using certificateDir folder "/var/lib/minikube/certs"
[certs] Using existing ca certificate authority
[certs] Using existing apiserver certificate and key on disk

stderr:
W0101 05:51:06.067129   10635 initconfiguration.go:119] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
	[WARNING DirAvailable--var-lib-minikube-etcd]: /var/lib/minikube/etcd is not empty
error execution phase certs/apiserver-kubelet-client: [certs] certificate apiserver-kubelet-client not signed by CA certificate ca: x509: certificate signed by unknown authority (possibly because of "crypto/rsa: verification error" while trying to verify candidate authority certificate "minikubeCA")
To see the stack trace of this error execute with --v=5 or higher

W0101 11:21:06.668924   21972 out.go:239] * 
W0101 11:21:06.669925   21972 out.go:239] ╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│                                                                                             │
│    * If the above advice does not help, please let us know:                                 │
│      https://github.com/kubernetes/minikube/issues/new/choose                               │
│                                                                                             │
│    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │
│                                                                                             │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯
I0101 11:21:06.673746   21972 out.go:177] 
W0101 11:21:06.674725   21972 out.go:239] X Exiting due to GUEST_START: failed to start node: wait: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables": Process exited with status 1
stdout:
[init] Using Kubernetes version: v1.26.3
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[certs] Using certificateDir folder "/var/lib/minikube/certs"
[certs] Using existing ca certificate authority
[certs] Using existing apiserver certificate and key on disk

stderr:
W0101 05:51:06.067129   10635 initconfiguration.go:119] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
	[WARNING DirAvailable--var-lib-minikube-etcd]: /var/lib/minikube/etcd is not empty
error execution phase certs/apiserver-kubelet-client: [certs] certificate apiserver-kubelet-client not signed by CA certificate ca: x509: certificate signed by unknown authority (possibly because of "crypto/rsa: verification error" while trying to verify candidate authority certificate "minikubeCA")
To see the stack trace of this error execute with --v=5 or higher

W0101 11:21:06.675232   21972 out.go:239] * 
W0101 11:21:06.676004   21972 out.go:239] ╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│                                                                                             │
│    * If the above advice does not help, please let us know:                                 │
│      https://github.com/kubernetes/minikube/issues/new/choose                               │
│                                                                                             │
│    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │
│                                                                                             │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯
I0101 11:21:06.677746   21972 out.go:177] 

* 
* ==> Docker <==
* -- Logs begin at Mon 2024-01-01 05:48:20 UTC, end at Mon 2024-01-01 05:51:37 UTC. --
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\". Proceed without further sandbox information."
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Failed to delete corrupt checkpoint for sandbox endpoint=\"/var/run/cri-dockerd.sock\": invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\". Proceed without further sandbox information."
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Failed to delete corrupt checkpoint for sandbox endpoint=\"/var/run/cri-dockerd.sock\": invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\". Proceed without further sandbox information."
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="CNI failed to delete loopback network: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\"Failed to delete corrupt checkpoint for sandboxpodSandboxIDendpoint=\"/var/run/cri-dockerd.sock\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting network when building cni runtime conf: could not retrieve port mappings: invalid key: \"endpoint=\\\"/var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Failed to delete corrupt checkpoint for sandbox URL=\"unix:///var/run/cri-dockerd.sock\": invalid key: \"URL=\\\"unix:///var/run/cri-dockerd.sock\\\"\""
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker 8253b571868f61918fd0bc96c47f2292e1f0f5c7b749890ead86a64794bde6e0}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker 8253b571868f61918fd0bc96c47f2292e1f0f5c7b749890ead86a64794bde6e0}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker 8253b571868f61918fd0bc96c47f2292e1f0f5c7b749890ead86a64794bde6e0}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker 8253b571868f61918fd0bc96c47f2292e1f0f5c7b749890ead86a64794bde6e0}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker 8253b571868f61918fd0bc96c47f2292e1f0f5c7b749890ead86a64794bde6e0}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker 2ca82f9f9afd5a5db7e0569ccb5116d578234bf4607816c4ea3f2e2a2d440072}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker 2ca82f9f9afd5a5db7e0569ccb5116d578234bf4607816c4ea3f2e2a2d440072}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker 2ca82f9f9afd5a5db7e0569ccb5116d578234bf4607816c4ea3f2e2a2d440072}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker 2ca82f9f9afd5a5db7e0569ccb5116d578234bf4607816c4ea3f2e2a2d440072}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker 2ca82f9f9afd5a5db7e0569ccb5116d578234bf4607816c4ea3f2e2a2d440072}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongo-express-deployment-5bcd46fcff-xh7tx from network {docker 080b0bf3b8dad26fbbd665e434b5f479e2c7ef8b7d782a374eecf58472c6b397}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongo-express-deployment-5bcd46fcff-xh7tx from network {docker 080b0bf3b8dad26fbbd665e434b5f479e2c7ef8b7d782a374eecf58472c6b397}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongo-express-deployment-5bcd46fcff-xh7tx from network {docker 080b0bf3b8dad26fbbd665e434b5f479e2c7ef8b7d782a374eecf58472c6b397}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongo-express-deployment-5bcd46fcff-xh7tx from network {docker 080b0bf3b8dad26fbbd665e434b5f479e2c7ef8b7d782a374eecf58472c6b397}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongo-express-deployment-5bcd46fcff-xh7tx from network {docker 080b0bf3b8dad26fbbd665e434b5f479e2c7ef8b7d782a374eecf58472c6b397}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 2dc10c2d89c1371400f213e649de2a17a0a3bc910fbed63dcdd55f0c493dbcab}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 2dc10c2d89c1371400f213e649de2a17a0a3bc910fbed63dcdd55f0c493dbcab}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 2dc10c2d89c1371400f213e649de2a17a0a3bc910fbed63dcdd55f0c493dbcab}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 2dc10c2d89c1371400f213e649de2a17a0a3bc910fbed63dcdd55f0c493dbcab}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 2dc10c2d89c1371400f213e649de2a17a0a3bc910fbed63dcdd55f0c493dbcab}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 569abcf1ed19542d49ecc5f78b6cbde167ce3aa7a26e7c99036354cb98b70f86}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 569abcf1ed19542d49ecc5f78b6cbde167ce3aa7a26e7c99036354cb98b70f86}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 569abcf1ed19542d49ecc5f78b6cbde167ce3aa7a26e7c99036354cb98b70f86}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 569abcf1ed19542d49ecc5f78b6cbde167ce3aa7a26e7c99036354cb98b70f86}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/mongodb-deployment-5d966bd9d6-fl4cr from network {docker 569abcf1ed19542d49ecc5f78b6cbde167ce3aa7a26e7c99036354cb98b70f86}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker b5f5af246f0fc84180c8150fd417a735614c915875443e3dc228b46e46f522f9}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker b5f5af246f0fc84180c8150fd417a735614c915875443e3dc228b46e46f522f9}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker b5f5af246f0fc84180c8150fd417a735614c915875443e3dc228b46e46f522f9}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker b5f5af246f0fc84180c8150fd417a735614c915875443e3dc228b46e46f522f9}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod kube-system/coredns-787d4945fb-7rs9g from network {docker b5f5af246f0fc84180c8150fd417a735614c915875443e3dc228b46e46f522f9}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker dd31196d0e2fb1ac3112fe82fe9da52e6773f6d2b8d5f4d751861ceba54bb461}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker dd31196d0e2fb1ac3112fe82fe9da52e6773f6d2b8d5f4d751861ceba54bb461}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker dd31196d0e2fb1ac3112fe82fe9da52e6773f6d2b8d5f4d751861ceba54bb461}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker dd31196d0e2fb1ac3112fe82fe9da52e6773f6d2b8d5f4d751861ceba54bb461}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Jan 01 05:51:05 minikube cri-dockerd[7986]: time="2024-01-01T05:51:05Z" level=error msg="Error deleting pod default/nginx-depl-56cb8b6d7-dtrfn from network {docker dd31196d0e2fb1ac3112fe82fe9da52e6773f6d2b8d5f4d751861ceba54bb461}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID
d6247e994e432       2d2fb2cabc8fa       4 months ago        Exited              mongo-express       2                   080b0bf3b8dad
bf81c95051d69       fb5fba25b25a2       4 months ago        Exited              mongodb             1                   2dc10c2d89c13
f0b0eb42e1a0b       2d2fb2cabc8fa       4 months ago        Exited              mongo-express       1                   080b0bf3b8dad
9824d2140e3bb       89da1fb6dcb96       4 months ago        Exited              nginx               3                   8253b571868f6
150b91fc9e61c       5185b96f0becf       4 months ago        Exited              coredns             4                   2ca82f9f9afd5
767aca15918a2       fb5fba25b25a2       5 months ago        Exited              mongodb             0                   569abcf1ed195
28e049ff331c7       021283c8eb95b       5 months ago        Exited              nginx               2                   dd31196d0e2fb
f6323d482fd35       5185b96f0becf       5 months ago        Exited              coredns             3                   b5f5af246f0fc

* 
* ==> coredns [150b91fc9e61] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = 8846d9ca81164c00fa03e78dfcf1a6846552cc49335bc010218794b8cfaf537759aa4b596e7dc20c0f618e8eb07603c0139662b99dfa3de45b176fbe7fb57ce1
CoreDNS-1.9.3
linux/amd64, go1.18.2, 45b0a11
[INFO] 127.0.0.1:48405 - 6397 "HINFO IN 1169960737555030009.8731472993072003794. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.062475444s
[INFO] 10.244.0.14:58594 - 6655 "A IN mongodb-service.default.svc.cluster.local. udp 59 false 512" NOERROR qr,aa,rd 116 0.00032816s
[INFO] 10.244.0.15:47928 - 32630 "A IN compass.mongodb.com.default.svc.cluster.local. udp 63 false 512" NXDOMAIN qr,aa,rd 156 0.000306399s
[INFO] 10.244.0.15:36127 - 56950 "A IN compass.mongodb.com.svc.cluster.local. udp 55 false 512" NXDOMAIN qr,aa,rd 148 0.00019848s
[INFO] 10.244.0.15:60639 - 51934 "A IN compass.mongodb.com.cluster.local. udp 51 false 512" NXDOMAIN qr,aa,rd 144 0.00010644s
[INFO] 10.244.0.15:52494 - 27762 "A IN api.segment.io.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000199511s
[INFO] 10.244.0.15:44689 - 16445 "A IN api.segment.io.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.0001619s
[INFO] 10.244.0.15:54106 - 8266 "A IN api.segment.io.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000115952s
[INFO] 10.244.0.15:36946 - 9664 "A IN api.segment.io. udp 32 false 512" NOERROR qr,rd,ra 122 0.031988767s
[INFO] 10.244.0.15:44784 - 36870 "A IN compass.mongodb.com. udp 37 false 512" NOERROR qr,rd,ra 306 0.077905099s
[INFO] 10.244.0.15:35860 - 230 "A IN api.segment.io.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000298534s
[INFO] 10.244.0.15:54095 - 45217 "A IN api.segment.io.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000229897s
[INFO] 10.244.0.15:53279 - 56713 "A IN api.segment.io.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000167626s
[INFO] 10.244.0.15:60337 - 9934 "A IN api.segment.io. udp 32 false 512" NOERROR qr,aa,rd,ra 122 0.000322375s
[INFO] 10.244.0.15:37389 - 54246 "A IN raw.githubusercontent.com.default.svc.cluster.local. udp 69 false 512" NXDOMAIN qr,aa,rd 162 0.000402064s
[INFO] 10.244.0.15:58832 - 24648 "A IN raw.githubusercontent.com.svc.cluster.local. udp 61 false 512" NXDOMAIN qr,aa,rd 154 0.000380333s
[INFO] 10.244.0.15:34699 - 40610 "A IN raw.githubusercontent.com.cluster.local. udp 57 false 512" NXDOMAIN qr,aa,rd 150 0.000347312s
[INFO] 10.244.0.15:37721 - 41053 "A IN raw.githubusercontent.com. udp 43 false 512" NOERROR qr,rd,ra 207 0.036890649s
[INFO] 10.244.0.14:51960 - 22380 "A IN mongodb-service.default.svc.cluster.local. udp 59 false 512" NOERROR qr,aa,rd 116 0.000278909s

* 
* ==> coredns [f6323d482fd3] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = 8846d9ca81164c00fa03e78dfcf1a6846552cc49335bc010218794b8cfaf537759aa4b596e7dc20c0f618e8eb07603c0139662b99dfa3de45b176fbe7fb57ce1
CoreDNS-1.9.3
linux/amd64, go1.18.2, 45b0a11
[INFO] 127.0.0.1:37790 - 15568 "HINFO IN 8945468823559135233.1670751734280802186. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.049624591s
[INFO] 10.244.0.12:49470 - 53556 "A IN api.segment.io.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.016521932s
[INFO] 10.244.0.12:33932 - 42062 "A IN compass.mongodb.com.svc.cluster.local. udp 55 false 512" NXDOMAIN qr,aa,rd 148 0.001980343s
[INFO] 10.244.0.12:60040 - 23315 "A IN compass.mongodb.com.cluster.local. udp 51 false 512" NXDOMAIN qr,aa,rd 144 0.000385437s
[INFO] 10.244.0.12:56371 - 49800 "A IN api.segment.io.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000284762s
[INFO] 10.244.0.12:34794 - 38676 "A IN api.segment.io.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.001951238s
[INFO] 10.244.0.12:50212 - 31790 "A IN compass.mongodb.com.default.svc.cluster.local. udp 63 false 512" NXDOMAIN qr,aa,rd 156 0.020316117s
[INFO] 10.244.0.12:60393 - 62185 "A IN api.segment.io. udp 32 false 512" NOERROR qr,rd,ra 122 0.054472553s
[INFO] 10.244.0.12:47233 - 55705 "A IN compass.mongodb.com. udp 37 false 512" NOERROR qr,rd,ra 306 0.073310001s
[INFO] 10.244.0.12:39940 - 26662 "A IN api.segment.io.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000318683s
[INFO] 10.244.0.12:35611 - 34482 "A IN api.segment.io.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000095095s
[INFO] 10.244.0.12:52924 - 24629 "A IN api.segment.io.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000075835s
[INFO] 10.244.0.12:53233 - 27829 "A IN api.segment.io. udp 32 false 512" NOERROR qr,aa,rd,ra 122 0.000134991s
[INFO] 10.244.0.13:36362 - 46603 "A IN mongodb-service.default.svc.cluster.local. udp 59 false 512" NOERROR qr,aa,rd 116 0.000622154s
[INFO] 10.244.0.13:37438 - 46447 "A IN mongodb-service.default.svc.cluster.local. udp 59 false 512" NOERROR qr,aa,rd 116 0.000913435s

* 
* ==> describe nodes <==
* 
* ==> dmesg <==
* [Jan 1 05:39] PCI: Fatal: No config space access function found
[  +0.014263] PCI: System does not support PCI
[  +0.195426] kvm: already loaded the other module
[  +1.364596] FS-Cache: Duplicate cookie detected
[  +0.000333] FS-Cache: O-cookie c=00000004 [p=00000002 fl=222 nc=0 na=1]
[  +0.000240] FS-Cache: O-cookie d=0000000045253289{9P.session} n=00000000b8267276
[  +0.000261] FS-Cache: O-key=[10] '34323934393337343535'
[  +0.000181] FS-Cache: N-cookie c=00000005 [p=00000002 fl=2 nc=0 na=1]
[  +0.000215] FS-Cache: N-cookie d=0000000045253289{9P.session} n=0000000030c6e3ae
[  +0.000421] FS-Cache: N-key=[10] '34323934393337343535'
[  +0.001433] FS-Cache: Duplicate cookie detected
[  +0.000283] FS-Cache: O-cookie c=00000004 [p=00000002 fl=222 nc=0 na=1]
[  +0.000258] FS-Cache: O-cookie d=0000000045253289{9P.session} n=00000000b8267276
[  +0.000279] FS-Cache: O-key=[10] '34323934393337343535'
[  +0.000287] FS-Cache: N-cookie c=00000006 [p=00000002 fl=2 nc=0 na=1]
[  +0.000371] FS-Cache: N-cookie d=0000000045253289{9P.session} n=00000000e4385040
[  +0.000374] FS-Cache: N-key=[10] '34323934393337343535'
[  +0.506277] 9pnet_virtio: no channels available for device drvfs
[  +0.001040] WSL (1) WARNING: mount: waiting for virtio device drvfs
[  +0.160112] WSL (1) ERROR: ConfigApplyWindowsLibPath:2529: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000006]  failed 2
[  +0.018151] 9pnet_virtio: no channels available for device drvfs
[  +0.026603] WSL (1) WARNING: mount: waiting for virtio device drvfs
[  +0.100483] 9pnet_virtio: no channels available for device drvfs
[  +0.118078] WSL (1) WARNING: /usr/share/zoneinfo/Asia/Calcutta not found. Is the tzdata package installed?
[  +0.413598] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000571] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000385] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000587] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2
[  +1.207057] 9pnet_virtio: no channels available for device drvfs
[  +0.000380] WSL (1) WARNING: mount: waiting for virtio device drvfs
[  +0.193592] WSL (2) ERROR: UtilCreateProcessAndWait:663: /bin/mount failed with 2
[  +0.000703] WSL (1) ERROR: UtilCreateProcessAndWait:685: /bin/mount failed with status 0xff00

[  +0.000716] WSL (1) ERROR: ConfigMountFsTab:2581: Processing fstab with mount -a failed.
[  +0.001726] WSL (1) ERROR: ConfigApplyWindowsLibPath:2529: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000003]  failed 2
[  +0.008919] 9pnet_virtio: no channels available for device drvfs
[  +0.000468] WSL (1) WARNING: mount: waiting for virtio device drvfs
[  +0.200127] WSL (1) WARNING: /usr/share/zoneinfo/Asia/Calcutta not found. Is the tzdata package installed?
[  +0.003524] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.001315] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.018103] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.021591] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2

* 
* ==> kernel <==
*  05:51:37 up 11 min,  0 users,  load average: 0.24, 0.70, 0.42
Linux minikube 5.15.133.1-microsoft-standard-WSL2 #1 SMP Thu Oct 5 21:02:42 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 20.04.5 LTS"

* 
* ==> kubelet <==
* -- Logs begin at Mon 2024-01-01 05:48:20 UTC, end at Mon 2024-01-01 05:51:37 UTC. --
-- No entries --

